\chapter{Introduction}

\section{Science as an incremental, open process}

The history of science is all too often taught as a chronological list of discoveries. There is undeniable value in this approach as it reflects the arrow of complexity of notions. However, it leads to a very simplified image of the development of scientific knowledge: one big idea bringing over the next and so on. On page~\pageref{table:historyDiff}, I too show the history of diffraction as a table of chronological events. These are big shift events, which radically and permanently changed the way future science was to be done in this area. A good number of names in this table were awarded for their significant contribution with Nobel prizes. Nevertheless, the table is clearly a gross simplification of history, omitting, due to lack of space, the incremental refinement and maintenance work that supported and propelled the bigger ideas. It is quite common for important work of individual voices to be wiped away from science history as we associate a breakthrough to a single name or even to a small group of people. Seeing the bigger picture is, undeniably, worthwhile, but we must not mistake it for the full picture.

The ``unremarkable'' work done by the rest of the community, not awarded prestigious prizes, is not less important for the advancement of science. Quite the opposite. Neither science nor culture truly advance in big steps. In a recent study published in Nature, Miu \etal~\cite{Miu2018} looked at the way pieces of software get improved by a community of developers in a simulation of cumulative culture evolution. One of the observations was that the vast majority of advances are of an incremental type and not, as the scientific community expect, leaps in knowledge. Observing the strong positive breakthrough bias of scientific publishing, one would find it hard to assume that enough credit is given to the ``tweakers''. 

Another critical observation was that big changes in the paradigm are more likely to turn out unsuccessful than smaller tweaks. Remember the Nobel prize in medicine awarded for the ``discovery'' of brain lobotomies\footnote{``for his discovery of the therapeutic value of leucotomy in certain psychoses''-- The Nobel Prize in Physiology or Medicine 1949~\cite{Nobel49}.}? Thankfully, neuroscience moved away from this particular scientific breakthrough. And it did that with small, incremental improvements on the understanding of the brain. Any sort of conversation about the development of science focused only on the leaps of knowledge must ultimately be misrepresenting the scientific process.


In this paradigm of scientific value misrepresentation, scientific code suffers perhaps even more. The philosopher Daniel C. Dennett, in his latest book \textit{From bacteria to Bach and back}~\cite{Dennett} makes the case that evolution is not only a good protocol for developing fit biological organisms but can, in fact, be successfully applied to a variety of concepts, perhaps, he argues, consciousness, the human mind and even code development. The latter analogy I find compelling. Similarly to adaptable organism having emerged from surviving a variety of conditions, the power of good code stands in the number of iterations it went through. Of course, we cannot wait around for functional code to ``occur'' as the results of tens of millions of years of iterations, and, after all, we expect developers to be somewhat wiser than the random processes occurring in nature. Nevertheless, in the end, each iterative step has the chance to rectify errors or limitations in the code, weed out unnecessary/old lines and replace them with new, more optimised, features. Established software tends to be software reviewed by many pairs of eyes. Yet, scientific software continues to be developed and  maintained by small groups and destined to see the light of only a handful of iterations.  


To add insult to injury, scientific code is rarely developed to be open and even more rarely made easily accessible. Here is another anecdotal evidence of why I think this a counter-intuitive way of following the scientific method. Two condensed matter groups set out, independently, to predict the behaviour of supercooled water, and, even though they implemented the same method, their results contradicted each other for seven straight years~\cite{supercool}. During this time, while the groups were in contact to one another, the actual lines of code never changed hands. When it finally did, a bug was discovered by the ``competin'' team in just a few months. I'm pointing out that we could have known in a few months, not seven long years, that water is predicted to change phase when supercooled. When scientific groups working in the same field do not collaborate with each other for whatever reason, it is science that suffers.


In the light of all these, I want my thesis work to make a positive tweak in the endeavour of making electron diffraction in the SEM a well-understood phenomena in the electron microscopy community. I aim for this work to aid the understanding of why we can observe and how we can study dislocations in the SEM and I do not expect it to be the definitive attempt. For these reasons I tried to make this document as accessible as possible for whoever wants to continue on this journey. I tried to explain in depth the building blocks I used and why I chose them, I provide access to whatever code I ran or wrote and I offer a small collection of extra materials. May your code and science be even a little bit better than mine!



\section{Implementations}
\todo{add python and fortran instruction}

I will refer throughout this document to supplementary pieces of code, most in \emph{Python} and some in \emph{Fortran95}. I will try to describe in detail what they do, sometimes I will include pseudocode and other times I will just state the relevant equations. They can all be found on my, otherwise rather pristine, public GitHub repository~\cite{myGitHub}. 

The Python scripts have been written in Python 2 which can be easily installed on Ubuntu machines from the package manager or by typing in 18.04 or later:
\begin{verbatim}
$ apt install python-minimal
\end{verbatim}
Files containing Python script can be easily recognised from the \textit{.py} file type and can be ran with with:
\begin{verbatim}
$ python filename.py
\end{verbatim}

To run Fortran code on a Ubuntu machine use the gfortran compiler, which again can be found in the package manager or can be installed via:
\begin{verbatim}
$ apt install gfortran
\end{verbatim}

For the smaller scripts I use \href{http://jupyter.org}{\texttt{Jupyter}}~\cite{Jupyter} notebooks written in Python. I will assume the reader has Python 2.7 or greater installed. The \href{https://anaconda.org/}{\texttt{Anaconda}} Python distribution~\cite{Conda} ships with Jupyter among other packages useful for scientific computation. However, if you have Python already installed then you can use the package manager \href{https://pypi.org/project/pip/}{\texttt{pip}} to add new libraries:
\begin{verbatim}
$ pip install jupyter
\end{verbatim}
To start a Jupyter notebook kernel you just type:
\begin{verbatim}
$ jupyter notebook
\end{verbatim}
And navigate to the desired script file. Individual cells are compiled with \texttt{Shift} + \texttt{Enter}.

In some notebooks I use the \href{https://plot.ly/}{\texttt{plotly}} package ~\cite{Plotly} for plotting. These figures are interactive but do require an account on the \href{https://plot.ly/}{\texttt{plotly} website}\footnote{ \texttt{Plotly} website url is \href{https://plot.ly/}{https://plot.ly/}.}.  

\todo{make info}
\section{Thesis structure}

\info{to write thesis structure}
